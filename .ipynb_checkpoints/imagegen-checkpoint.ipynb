{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "955fe8c5-070d-404b-b6ac-51881b8c121c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "import torch\n",
    "from torch import tensor\n",
    "import torch.nn\n",
    "import numpy\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ff0512-fbb5-4917-8a60-3da9c307b272",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.5,), (0.5,)),\n",
    "                              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a9ce921-2ca1-47cb-ae15-5f9b2e5ab376",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('mnist', download=True, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "099b5f3d-c226-4f34-bf64-299cb1d57484",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25b3606a-a822-4ab1-a61d-21229b5ad916",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_sizes = [128, 64]\n",
    "output_size = 10\n",
    "model = nn.Sequential(nn.Linear(input_size, hidden_sizes[0]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[0], hidden_sizes[1]),\n",
    "                      nn.ReLU(),\n",
    "                      nn.Linear(hidden_sizes[1], output_size),\n",
    "                      nn.LogSoftmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "85538727-62cd-415f-82d1-723267c551b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "images, labels = next(iter(trainloader))\n",
    "images = images.view(images.shape[0], -1)\n",
    "\n",
    "\n",
    "\n",
    "logps = model(images) #log probabilities\n",
    "loss = criterion(logps, labels) #calculate the NLL loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "03b393d6-84f3-452b-9cb0-8bf0caefed01",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-988dfddabd98>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0;31m# Flatten MNIST images into a 784 long vector\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, pic)\u001b[0m\n\u001b[1;32m    102\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mConverted\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mto_tensor\u001b[0;34m(pic)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mByteTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m255\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr=0.003, momentum=0.9)\n",
    "time0 = time()\n",
    "epochs = 15\n",
    "for e in range(epochs):\n",
    "    running_loss = 0\n",
    "    for images, labels in trainloader:\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "    \n",
    "        # Training pass\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output = model(images)\n",
    "        loss = criterion(output, labels)\n",
    "        \n",
    "        #This is where the model learns by backpropagating\n",
    "        loss.backward()\n",
    "        \n",
    "        #And optimizes its weights here\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "    else:\n",
    "        print(\"Epoch {} - Training loss: {}\".format(e, running_loss/len(trainloader)))\n",
    "print(\"\\nTraining Time (in minutes) =\",(time()-time0)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3d487305-535c-4286-a797-5d66f8fc6d85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Digit = tensor([[4.7386e-05, 4.9454e-01, 9.9990e+03, 4.7777e-01, 2.5687e-12, 1.5470e-04,\n",
      "         1.2602e-06, 6.8492e-02, 1.7302e-03, 1.2284e-07]]) 2\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(trainloader))\n",
    "\n",
    "img = images[0].view(1, 784)\n",
    "with torch.no_grad():\n",
    "    logps = model(img)\n",
    "\n",
    "ps = torch.exp(logps)\n",
    "probab = list(ps.numpy()[0])\n",
    "print(\"Predicted Digit =\", ps * 10000, probab.index(max(probab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e796bc06-7486-42b3-8516-be39343c34ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, './my_mnist_model.pt') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b4303474-8963-430c-9e3e-3fddd78f5869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        ...,\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.],\n",
      "        [-1., -1., -1.,  ..., -1., -1., -1.]])\n"
     ]
    }
   ],
   "source": [
    "print(images.view(images.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "d6e35dc6-9f2a-4466-b904-9439e756c2eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc0dd2b53a0>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].reshape((28, 28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9807c378-46da-4345-86ab-0f668faf53c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
